{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8296aa",
   "metadata": {},
   "source": [
    "# Previsão de Saída e Permanência de Clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ff9d2",
   "metadata": {},
   "source": [
    "Nesta análise iremos prever se os clientes do Banco Beta vão permanecer ou cancelar seus serviços com base em vários fatores, incluindo sua pontuação de crédito, localização geográfica, gênero, idade, tempo de relacionamento com o banco, saldo em conta, número de produtos utilizados, posse de cartão de crédito, atividade da conta e salário estimado. Para isso, usaremos um conjunto de dados que contém informações relevantes sobre os clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd973b5",
   "metadata": {},
   "source": [
    "## Sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e0e5a",
   "metadata": {},
   "source": [
    "1. [Iniciação](#inic)\n",
    "\n",
    "2. [Pré-processamento de Dados](#ppd)\n",
    "\n",
    "    A. [Excluindo Colunas](#ec)\n",
    "\n",
    "    B. [Valores Ausentes](#va)\n",
    "\n",
    "    C. [Colunas Categóricas](#cc)\n",
    "\n",
    "    D. [Colunas Numéricas](#cn)\n",
    "\n",
    "    E. [Features, Target e Divisão de Dados](#ftdd)\n",
    "\n",
    "3. [Modelo sem Balanceamento de Classe](#msbc)\n",
    "\n",
    "    A. [Árvore de Decisão](#ad)\n",
    "\n",
    "    B. [Floresta Aleatória](#fa)\n",
    "\n",
    "    C. [Regressão Logística](#rl)\n",
    "\n",
    "4. [Balanceamento de Classes](#bc)\n",
    "\n",
    "    A. [Ajuste de Classe Ponderada](#acp)\n",
    "\n",
    "    B. [Superamostragem](#sa)\n",
    "\n",
    "5. [Teste Final](#tf)\n",
    "\n",
    "6. [Conclusão](#co)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32172c59",
   "metadata": {},
   "source": [
    "## Iniciação <a id=\"inic\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0da2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee658ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453a196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5c585",
   "metadata": {},
   "source": [
    "Utilizaremos a coluna `Exited` como `target` para prever a saída de clientes, enquanto as demais colunas do conjunto de dados serão utilizadas como `features` para a criação do modelo. Para preparar os dados para a análise, primeiro é necessário preencher os valores ausentes na coluna `Tenure`. Em seguida, para as colunas categóricas, devemos criar variáveis dummy. Por fim, padronizar as colunas numéricas, exceto as que contêm valores binários, como `HasCrCard` e `IsActiveMember`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241de31",
   "metadata": {},
   "source": [
    "## Pré-processamento de Dados <a id=\"ppd\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e1db5",
   "metadata": {},
   "source": [
    "### Excluindo Colunas <a id=\"ec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2db8b",
   "metadata": {},
   "source": [
    "Existem três colunas no conjunto de dados que não são relevantes para a análise: `RowNumber`, `CustomerId` e `Surname`. A coluna `RowNumber` é apenas uma numeração sequencial para cada linha do conjunto de dados, enquanto `CustomerId` e `Surname` são identificadores únicos para cada cliente. Essas informações não são úteis para o treinamento do modelo, portanto, podemos descartá-las para simplificar a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c192bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68b97a",
   "metadata": {},
   "source": [
    "### Valores Ausentes <a id=\"va\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80440866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff93cc56",
   "metadata": {},
   "source": [
    "Após notarmos os valores ausentes iremos preenchê-los com o valor da mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c7434d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())\n",
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b38d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb5725",
   "metadata": {},
   "source": [
    "Valores preenchidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dfe11d",
   "metadata": {},
   "source": [
    "### Colunas Categóricas <a id=\"cc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29f03c",
   "metadata": {},
   "source": [
    "Analisaremos as 2 colunas categóricas `Geography` e `Gender` e seus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5422d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bece0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534e219",
   "metadata": {},
   "source": [
    "Observados os valores das colunas categóricas `Geography` e `Gender` temos em `Geography` 3 valores:\n",
    "`Spain`, `Germany` e `France`. Ao criar as variáveis dummy para essa coluna, ela será substituída por 3 colunas: `Geography_Spain`, `Geography_Germany` e `Geography_France`. Cada coluna terá o valor `1` na observação em que a coluna `Geography` tiver o país correspondente como valor e, caso contrário, o valor será `0`. O mesmo será feito para a coluna `Gender`. Para criar as variáveis dummy, será usado a função `pd.get_dummies` em toda a tabela `data`, já que essas são as únicas colunas categóricas. Podemos descartar uma das colunas dummy para ambos os cenários, porque um valor `0` para `Spain` e `Germany`, por exemplo, implica diretamente um valor `1` para `France`. Isso pode ser feito configurando o parâmetro `drop_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06715552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d184e78",
   "metadata": {},
   "source": [
    "### Colunas Numéricas <a id=\"cn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a1518",
   "metadata": {},
   "source": [
    "As colunas numéricas em questão são `CreditScore`, `Age`, `Tenure`, `Balance`, `NumOfProducts` e `EstimatedSalary`. Como essas variáveis não possuem uma escala definida, precisamos escaloná-las para que tenham a mesma importância no modelo. Para fazer isso, usaremos a função `StandardScaler()`, que ajustará as colunas numéricas através do método `fit()` e as transformará em desvios padrão. Dessa forma, é evitado que variáveis com alta dispersão tenham mais peso no modelo do que as outras. Só então, teremos os valores escalonados e prontos para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0265456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221  0.293517 -1.086246 -1.225848      -0.911583          1   \n",
       "1    -0.440036  0.198164 -1.448581  0.117350      -0.911583          0   \n",
       "2    -1.536794  0.293517  1.087768  1.333053       2.527057          1   \n",
       "3     0.501521  0.007457 -1.448581 -1.225848       0.807737          0   \n",
       "4     2.063884  0.388871 -1.086246  0.785728      -0.911583          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1         0.021886       1                  0   \n",
       "1               1         0.216534       0                  0   \n",
       "2               0         0.240687       1                  0   \n",
       "3               0        -0.108918       0                  0   \n",
       "4               1        -0.365276       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data[numeric])\n",
    "data[numeric] = scaler.transform(data[numeric])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85709a1b",
   "metadata": {},
   "source": [
    "### Features, Target e Divisão dos Dados <a id=\"ftdd\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c49e7a",
   "metadata": {},
   "source": [
    "Definiremos a variável objetivo (target) que será a coluna `Exited`, enquanto as outras colunas serão as características (features). Para avaliar o desempenho do modelo, dividiremos o conjunto de dados em conjuntos de treinamento, validação e teste, com proporções de `60%`, `20%` e `20%`, respectivamente. Para tal, usaremos a função `train_test_split()` duas vezes. Na primeira vez, dividiremos o conjunto de dados em um conjunto de treinamento e um segundo conjunto definindo o parâmetro `test_size=0.4` (que representa a porcentagem do conjunto de dados que será o segundo conjunto). Na segunda vez, dividiremos o segundo conjunto em dois conjuntos iguais (`test_size=0.5`) para obter os conjuntos de validação (20% do conjunto de dados original) e teste (20% do conjunto de dados original). O `random_state` será definido como `12345` e que será mantido no treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ff85aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 6000 2000 2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "features = data.drop('Exited', axis=1)\n",
    "target = data['Exited']\n",
    "features_train, features_test_valid, target_train, target_test_valid = train_test_split(features, target,\\\n",
    "test_size=0.4, random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_test_valid, \\\n",
    "target_test_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "print(len(features_train), len(target_train), len(features_valid), len(target_valid), len(features_test), \\\n",
    "len(target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff816ec1",
   "metadata": {},
   "source": [
    "## Modelo sem Balanceamento de Classe <a id=\"msbc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683c0884",
   "metadata": {},
   "source": [
    "### Árvore de Decisão <a id=\"ad\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10679978",
   "metadata": {},
   "source": [
    "Utilizaremos a função `DecisiontreeClassifier()`. Vamos definir dois hiperparâmetros: `random_state` e `max_depth`. O `random_state` deve ser o mesmo em todos os casos, portanto, vamos atribuir um valor fixo (12345). O `max_depth` é o hiperparâmetro que vamos ajustar. Vamos percorrer uma série de valores para o `max_depth` (de 1 a 10) e obter a pontuação `f1` e `AUC-ROC`, ambas métricas de qualidade do modelo. O `f1_score` processa o alvo do conjunto de validação e as previsões. A função `roc_auc_score` processa o alvo do conjunto de validação com as probabilidades da classe positiva de cada observação no conjunto de validação. Para isso, vamos utilizar a função `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad148413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 F1 score = 0.0 AUC-ROC score = 0.6925565119556736\n",
      "Max depth 2 F1 score = 0.5217391304347825 AUC-ROC score = 0.7501814673449512\n",
      "Max depth 3 F1 score = 0.4234875444839857 AUC-ROC score = 0.7973440741838507\n",
      "Max depth 4 F1 score = 0.5528700906344411 AUC-ROC score = 0.813428129858032\n",
      "Max depth 5 F1 score = 0.5406249999999999 AUC-ROC score = 0.8221680508592478\n",
      "Max depth 6 F1 score = 0.5696969696969697 AUC-ROC score = 0.8164631712023421\n",
      "Max depth 7 F1 score = 0.5320813771517998 AUC-ROC score = 0.8138530658907929\n",
      "Max depth 8 F1 score = 0.5454545454545454 AUC-ROC score = 0.8119854644656693\n",
      "Max depth 9 F1 score = 0.5633802816901409 AUC-ROC score = 0.7801515554775917\n",
      "Max depth 10 F1 score = 0.5406162464985994 AUC-ROC score = 0.7658451236699957\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):  \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    dt_pred_valid = dt_model.predict(features_valid)\n",
    "    \n",
    "    probabilities_valid = dt_model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    \n",
    "    print('Max depth', i, 'F1 score =', f1_score(target_valid, dt_pred_valid), 'AUC-ROC score =', \\\n",
    "         roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027cac5",
   "metadata": {},
   "source": [
    "Observamos que o melhor `f1_score` (~0,57) é obtido no `max_depth` 6, com um valor `AUC-ROC` de aproximadamente 0,82."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc854702",
   "metadata": {},
   "source": [
    "### Floresta Aleatória <a id=\"fa\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e7969",
   "metadata": {},
   "source": [
    "Para esse modelo usaremos a função `RandomForestClassifier()`. Mudaremos os hiperparâmetros `max_depth` e `n_estimatorsSerá`. Para o mesmo, criaremos uma lista vazia e, em seguida, um loop que percorra valores de `max_depth` e, dentro desse loop, outro loop que percorra valores de `n_estimators`. Usaremos esse loop para criar modelos com diferentes combinações de valores de `max_depth` e `n_estimators` que serão armazenados na lista. A partir dessa lista, escolheremos o modelo com a pontuação `f1` mais alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bec459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, n_estimators=10, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "rf = []\n",
    "for i in range(1, 11):\n",
    "    for j in range(10, 101, 10):\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        rf.append(rf_model)\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: f1_score(rf_model.predict(features_valid), target_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded19013",
   "metadata": {},
   "source": [
    "O modelo `Floresta Aleatória` com o maior `f1_score` tem os hiperparâmetros `max_depth=10` e `n_estimators=10`. Portanto, iremos treiná-lo especificamente com esses hiperparâmetros e obter um `f1_score` e um `roc_auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1603c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5869894099848714 AUC-ROC = 0.8461436676969979\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "\n",
    "print('F1 score =', f1_score(target_valid, best_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, probabilities_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cc22c",
   "metadata": {},
   "source": [
    "A pontuação `f1` é `~0.59`, com uma pontuação `AUC-ROC` de `~0.85`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618f5bd",
   "metadata": {},
   "source": [
    "### Regressão Logística <a id=\"rl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d009a1",
   "metadata": {},
   "source": [
    "Neste ultilizaremos a função `LogisticRegression()`. O `random_state` é o mesmo, mas os hiperparâmetros `max_depth` e `n_estimators` não se aplicam, portanto, só é necessário definir um solucionador (solver) que será o `liblinear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c154b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.33108108108108103 AUC-ROC = 0.7587497504824008\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_valid_pred = lr_model.predict(features_valid)\n",
    "\n",
    "probabilities_lr_valid = lr_model.predict_proba(features_valid)\n",
    "probabilities_lr_one_valid = probabilities_lr_valid[:, 1]\n",
    "\n",
    "print('F1 score =', f1_score(target_valid, lr_valid_pred), 'AUC-ROC =', \\\n",
    "     roc_auc_score(target_valid, probabilities_lr_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699fcc",
   "metadata": {},
   "source": [
    "- Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed768c",
   "metadata": {},
   "source": [
    "Entre os três modelos testados, o `Random Forest Classifier` com hiperparâmetros `max_depth=10` e `n_estimators=10` obteve o melhor desempenho, com a pontuação `f1` mais alta (cerca de 0,59) e `AUC-ROC` (cerca de 0,84). Portanto, este será o modelo usado daqui pra frente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be3382",
   "metadata": {},
   "source": [
    "## Balanceamento de Classes <a id=\"bc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb2759",
   "metadata": {},
   "source": [
    "Agora analisaremos o desequilíbrio de classe para determinar as proporções de cada classe no alvo do conjunto de treinamento. Para o mesmo, utilizaremos a função `value_counts()` com o parâmetro `normalize=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36de4213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.800667\n",
       "1    0.199333\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bf1d8",
   "metadata": {},
   "source": [
    "No conjunto de treinamento, a classe negativa (0) representa cerca de `80%` dos dados, enquanto a classe positiva (1) representa cerca de `20%`. Isso significa que há `quatro vezes` mais instâncias da classe `0` do que da classe `1`. Para abordar esse desequilíbrio de classe, veremos duas abordagens diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d83ea",
   "metadata": {},
   "source": [
    "### Ajuste de Classe Ponderada <a id=\"acp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bffbb1",
   "metadata": {},
   "source": [
    "Para utilizar essa abordagem, basta definir o hiperparâmetro `class_weight='balanced'` durante o treinamento do modelo. Isso fará com que a classe mais rara (1 neste caso) tenha mais peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "460c2a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6038647342995168 AUC-ROC = 0.8418065981526625\n"
     ]
    }
   ],
   "source": [
    "bal_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                      class_weight='balanced')\n",
    "bal_rf_model.fit(features_train, target_train)\n",
    "bal_rf_pred = bal_rf_model.predict(features_valid)\n",
    "\n",
    "proba_bal_rf_valid = bal_rf_model.predict_proba(features_valid)\n",
    "proba_bal_rf_one_valid = proba_bal_rf_valid[:, 1]\n",
    "\n",
    "print('F1 score =', f1_score(target_valid, bal_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_bal_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d689f",
   "metadata": {},
   "source": [
    "O valor de `f1 score` já está melhor do que antes, mas o valor `AUC-ROC` teve uma queda quase imperceptível. A taxa de verdadeiros positivos certamente diminuiu um pouco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb34cb",
   "metadata": {},
   "source": [
    "### Superamostragem <a id=\"sa\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29462d14",
   "metadata": {},
   "source": [
    "Nesse método, iremos basicamente repetir a classe minoritária e suas observações várias vezes até que ela esteja equilibrada em relação à outra classe. Constatamos anteriormente que existem `4 vezes` mais valores `0` do que `1`, então iremos repetir os valores `1` e suas observações `4 vezes` para igualar o número de zeros no conjunto de treinamento. Depois de fazer isso, precisaremos embaralhá-los usando a função `shuffle()` para que a aprendizagem não se torne muito fácil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a83ebf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9588, 11) (9588,)\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "\n",
    "print(features_upsampled.shape, target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecce63e",
   "metadata": {},
   "source": [
    "Agora podemos treinar o modelo usando as `features` e `targets` superamostradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03c3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5836909871244635 AUC-ROC = 0.8335694929197491\n"
     ]
    }
   ],
   "source": [
    "ups_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "ups_rf_model.fit(features_upsampled, target_upsampled)\n",
    "ups_rf_pred = ups_rf_model.predict(features_valid)\n",
    "\n",
    "proba_ups_rf_valid = ups_rf_model.predict_proba(features_valid)\n",
    "proba_ups_rf_one_valid = proba_ups_rf_valid[:, 1]\n",
    "\n",
    "print('F1 score =', f1_score(target_valid, ups_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_ups_rf_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee2ba16",
   "metadata": {},
   "source": [
    "O `f1 score` é menor do que o que obtivemos ao usar o ajuste de peso de classe. Notamos também que `AUC-ROC` diminuiu, mas com uma pequena diferença. A taxa de verdadeiros positivos deve ter diminuido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9560c68",
   "metadata": {},
   "source": [
    "- Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f89e0",
   "metadata": {},
   "source": [
    "Prosseguiremos com a abordagem de ajuste de peso de classe, já que ela apresenta a pontuação de `f1` mais alta, que é de `0,60`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff777a30",
   "metadata": {},
   "source": [
    "## Teste Final <a id=\"tf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee4523",
   "metadata": {},
   "source": [
    "Agora utilizaremos o modelo (com o ajuste dos pesos das classes) no conjunto de teste. Antes disso, é necessário treinar o modelo utilizando tanto o conjunto de treinamento quanto o de validação, e para isso, iremos combiná-los usando a função `pd.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8daa7b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6187214611872146 AUC-ROC = 0.8509656393397403\n"
     ]
    }
   ],
   "source": [
    "features_train_final = pd.concat([features_train] + [features_valid])\n",
    "target_train_final = pd.concat([target_train] + [target_valid])\n",
    "\n",
    "final_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                        class_weight='balanced')\n",
    "final_rf_model.fit(features_train_final, target_train_final)\n",
    "final_rf_pred = final_rf_model.predict(features_test)\n",
    "\n",
    "proba_rf_test = final_rf_model.predict_proba(features_test)\n",
    "proba_rf_one_test = proba_rf_test[:, 1]\n",
    "\n",
    "print('F1 score =', f1_score(target_test, final_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_test, proba_rf_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f20d7",
   "metadata": {},
   "source": [
    "A pontuação final de `f1` é `~0,62` que é maior que o limite mínimo de `0,59`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b843923",
   "metadata": {},
   "source": [
    "## Conclusão <a id=\"co\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8909b2",
   "metadata": {},
   "source": [
    "Após o processamento do conjunto de dados, que incluiu escalar colunas numéricas, preencher valores ausentes e obter colunas dummy a partir de variáveis categóricas, o conjunto de dados foi dividido em treino e teste. Então, treinamos três modelos de classificação diferentes, `Decision Tree`, `Random Forest` e `Logistic Regression Classifier`, sem considerar o desequilíbrio de classes, que apresentou uma proporção de `4:1`, com a classe negativa representando cerca de `80%` dos dados e a classe positiva cerca de `20%`.\n",
    "\n",
    "Após avaliar o desempenho dos modelos, foi constatado que o `Random Forest` apresentou a melhor métrica, com um alto valor de `f1-score` de aproximadamente `0,59` e um valor de AUC-ROC de `~0,85`. Em seguida, consideramos o desequilíbrio de classes e testamos duas abordagens para solucionar o problema: ajuste de peso de classe e superamostragem. Optamos pela primeira abordagem, que resultou em um `f1-score` mais alto de `0,59`, mesmo que a outra opção tivesse um valor `AUC-ROC` mais alto.\n",
    "\n",
    "Treinamos o modelo com os dados de treinamento e validação e o aplicamos ao conjunto de teste, obtendo um `f1-score` de `~0,62`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
